#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\begin_preamble
\lstdefinelanguage{scala}
{
 morekeywords={abstract,case,catch,class,def,%
    do,else,extends,false,final,finally,%
    for,if,implicit,import,match,mixin,%
    new,null,object,override,package,%
    private,protected,requires,return,sealed,%
    super,this,throw,trait,true,try,%
    type,val,var,while,with,yield},
  otherkeywords={=>,<-,<\%,<:,>:,\#,@},
  sensitive=true,
  morecomment=[l]{//},
  morecomment=[n]{/*}{*/},
  morestring=[b]",
  morestring=[b]',
  morestring=[b]"""
}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Light Weight Threads and Their Synchronization Primitives
\end_layout

\begin_layout Author
Tormod Hellen
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section*
Evaluation note
\end_layout

\begin_layout Standard
I want to be evaluated on both this report and the attached C code.
 
\end_layout

\begin_layout Section
memo to self: paste code with edit->paste special->plain text, fix conclusion
 on stm
\end_layout

\begin_layout Part
Introduction
\end_layout

\begin_layout Section
Goals
\end_layout

\begin_layout Standard
The goals of this project is to:
\end_layout

\begin_layout Enumerate
Give a desciption of the paradigms relevant to safe concurrency, where safe
 is defined as lacking race conditions and making deadlocks easier to handle
\end_layout

\begin_layout Enumerate
Present the leading edge of implementations and other things that should
 influence a modern concurrency abstraction framework
\end_layout

\begin_layout Enumerate
Give an overview over how threads, channels etc.
 work in modern implementations
\end_layout

\begin_layout Enumerate
Propose a mechanism for safe concurrency in C
\end_layout

\begin_layout Enumerate
Prototype the solution mentioned
\end_layout

\begin_layout Part
Background
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
There are many models of concurrency awailable to the modern engineer.
 The classic semaphore and its relative - lock - are the most native to
 the way our processors look, with shared memory between thread hardware.
 Others, like the actor model, copy a distributed architecture with several
 computers, all with their own memory, processors and network connections.
 Others still, like channel-concurrency, are based on formal or mathematical
 theorems.
 These are the three main means of concurrency, though others have been
 introduced.
 We will look at some of them here.
\end_layout

\begin_layout Subsection
Tl;DR
\end_layout

\begin_layout Itemize

\emph on
Semaphore
\emph default
: C, C++, Java etc.
 implement this style of concurrency.
 
\end_layout

\begin_deeper
\begin_layout Itemize
STM: Software Transactional Memory, or, for some architectures, simply Transacti
onal Memory, is a kind of optimistic semaphore technique where changes are
 rolled back and attempted again in case of conflict.
 Coupled with language features that prevent the sharing of non-transactional
 memory between threads it is a convenient, but computationally costly technique.
\end_layout

\end_deeper
\begin_layout Itemize

\emph on
Channel
\emph default
: This is the CSP family and its derivatives.
 Go, Rust and Occam have concurrency mechanisms based on channels.
 Focus on being deterministic and formally analyzable.
 Uses multi-sender, multi-receiver (first to read) synchronous channels.
\end_layout

\begin_layout Itemize

\emph on
Actor
\emph default
: Erlang and Akka implement this model.
 Intuitively suited for making distributed systems, with a focus on fault
 tolerance rather than fault avoidance.
 Both implementations eschew sophisticated error recovery mechanisms and
 instead prefer crashing and rebooting errant processes, a philosophy called
 
\begin_inset Quotes eld
\end_inset

let it crash
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Itemize

\emph on
Paralell statements
\emph default
: If you have multiple actions that you know can be done in paralell without
 communicating with each other, then proceeding when all are done, then
 there's no reason you shouldn't.
 Rust and Akka offer this as futures, Occam has par blocks and LabView has
 paralell pipes.
 There's also parallel transformations of lists, which is particularly easy
 to do for the programmer.
\end_layout

\begin_layout Itemize
Synchronous execution: Threads execute in synchrony, resulting in complete
 determinism.
 Esterel uses this.
\end_layout

\begin_layout Itemize
Lightweight threads that are less omputationally costly to deal with than
 OS threads, which in turn are less costly than processes.
 Details differ from implementation to implementation.
\end_layout

\begin_layout Section
Limitations
\end_layout

\begin_layout Standard
Rust is the newest and hottest language investigated in this project.
 It's developed by Mozilla as a replacement for C++.
 Rust 
\emph on
used to have
\emph default
 only lightweight threads, but due to the many features desirable for threads
 in Rust (ability to call C code etc.) the lightweight threads ended up being
 as heavy to run as OS threads, and Rust's lightweight threads have been
 pushed to a library outside the standard library.
 This illustrates an important point: OS threads are not heavyweight just
 to irritate us, they are heavyweight because they have features lightweight
 threads don't.
 Tradeoffs are necessary.
 There is no free lunch.
 This is also true for the synchronization abstractions.
\end_layout

\begin_layout Standard
Let there be no mistake: In switching from OS threads with semaphores to
 any of the higher abstractions we sacrifice flexibility and usually performance
 for the sake of safety and ease of programming.
 That's the disclaimer.
 Now for the good part: The end result can still be more performant and
 do more complicated things because the safety and ease of use lets us program
 less conservatively.
 It's a bit like going from a low-level language to a high-level one.
\end_layout

\begin_layout Section
Lightweight threads and synchronization
\end_layout

\begin_layout Standard
Lightweight threads and synchronization mechanisms are different things
 not really intimately linked.
 It's' quite possible to have one without 
\end_layout

\begin_layout Section
The Nature of a Lightweight Thread
\begin_inset Index idx
status open

\begin_layout Plain Layout
Lightweight Thread
\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Process > OS Thread > Lightweight Thread
\end_layout

\begin_layout Standard
OS threads are actually themselves lightweight when compared to another
 popular concurrency abstraction: processes.
 All processes run concurrently anyway, and moving information between them
 with inter-process communication (example: localhost) you suddenly have
 a heavyweight actor model: All that's old is new again, it seems.
 My point is that the quest for more efficient means of concurrency is hardly
 new, though it has acquired unusual urgency as single-core processor performanc
e gains are slowing down.
\end_layout

\begin_layout Paragraph
What does a lightweight thread look like? 
\end_layout

\begin_layout Standard
Well, the point of a lightweight thread is to be light - it can't have all
 the things an OS thread does.
 A POSIX thread holds the following things in memory
\begin_inset CommandInset citation
LatexCommand cite
key "key-1"

\end_inset

:
\end_layout

\begin_layout Itemize
Stack pointer 
\end_layout

\begin_layout Itemize
Registers 
\end_layout

\begin_layout Itemize
Scheduling properties (such as policy or priority) 
\end_layout

\begin_layout Itemize
Set of pending and blocked signals 
\end_layout

\begin_layout Itemize
Thread specific data such as the current execution stack.
\end_layout

\begin_layout Standard
Collectively, these things are called a thread context.
 A context switch is when a processor core pauses, switches its registers,
 points its stack pointer and program counter at the right memory adresses
 etc.
 and starts executing again.
 So lightweight threads, in order to be lightweight, have to sustain themselves
 on less than a thread context and/or have faster context switches, which
 are two goals with overlapping means.
 There are many ways from here: 
\end_layout

\begin_layout Itemize
Go's goroutines have no signals, but they do have a stack.
 The stack starts small and, like a vector, can be expanded by allocating
 a piece of memory somewhere else.
 By having a stack, goroutines are a bit like normal threads as they can
 be resumed after a pause.
\end_layout

\begin_layout Itemize
Akka's actors have no stack.
 How do they work then? The Java thread runs the actor's receive function
 until completion and then the stack is thrown away as the Java thread moves
 on to another actor.
 Clever and simple, but it requires a different way of programming than
 we're used to.
 See? Tradeoffs.
\end_layout

\begin_layout Section
CSP Theory
\begin_inset Index idx
status open

\begin_layout Plain Layout
CSP
\end_layout

\end_inset


\end_layout

\begin_layout Standard
This part is strictly optional.
 The Communicating Sequential Processes theory describes a way for parallel
 computation to be done in which the traditional shared-memory errors like
 race conditions are not possible.
 CSP introduces processes and events.
\end_layout

\begin_layout Section
The Conflict Between Fault Tolerance and Verification/Debugging
\end_layout

\begin_layout Standard
Formal verification is desireable in many safety-critical programs.
 Unfortunate side-effects of fault-tolerant systems, for example actor systems,
 is that they 
\end_layout

\begin_layout Enumerate
make the program's behaviour more complex 
\end_layout

\begin_layout Enumerate
hides fault from the developer at runtime.
\end_layout

\begin_layout Standard
Both are problems when we want to ensure correctness or debug the program
 at runtime.
 The first problem can be partly solved by using frameworks or languages
 where the added complexities can be assumed bug free, though you still
 need to superficially understand how they work.
 The second problem can be partly solved by using extensive logging.
 These techniques can make debugging such a complex system less hard than
 it would otherwise be, but the analysability of such a system can still
 be an unsolveable problem due to the amount of states the software can
 be in.
\end_layout

\begin_layout Standard
It is, in sum, unlikely that an implementation made using actor- or other
 fault-tolerant techniques can be verified directly, however using these
 models can help create systems that will resist non-software faults.
 Also, these tools can usually be used to emulate verifiable systems and
 although that's not as good as using a tool with built-in verifiable abstractio
ns, it may be better than constructing your own using semaphores and heavy
 threads.
\end_layout

\begin_layout Section
Semaphores
\begin_inset Index idx
status open

\begin_layout Plain Layout
Semaphores
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Semaphores, mutexes and locks operate mostly the same.
 They are atomic variables that the threads can use to negotiate access
 to values they want to mutate.
 Unfortunately the negotiation has to be written by the programmer and this
 process is notoriously difficult.
 The solution, as with manual memory management, is to be very very careful.
 Concurrent threads usually do not persist during the entire program, but
 are created for specific purposes and ended as soon as possible to keep
 complexity as low as possible.
\end_layout

\begin_layout Section
Software Transactional Memory
\begin_inset Index idx
status open

\begin_layout Plain Layout
Software Transactional Memory
\end_layout

\end_inset


\begin_inset Index idx
status open

\begin_layout Plain Layout
STM
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Software Transactional Memory, STM for short, is a very convenient way to
 get communication between threads going.
 
\begin_inset Quotes eld
\end_inset

You there!
\begin_inset Quotes erd
\end_inset

, one can imagine the salesman go, 
\begin_inset Quotes eld
\end_inset

You there programming with semaphores! Wouldn't it be great if you could
 just make the semaphores disappear? With some STM you can!
\begin_inset Quotes erd
\end_inset

 Gosh, sounds great, doesn't it? So how does STM work? Well, STM is, as
 the name implies, transactional.
 Hang on:
\end_layout

\begin_layout Enumerate
You lock, copy (to C1) and unlock the variable you want to perform a calculation
 on (O).
\end_layout

\begin_layout Enumerate
You perform the calculation 
\end_layout

\begin_layout Enumerate
If the calculation involves writing to the original variable, then you write
 the result to a new copy (C2)
\end_layout

\begin_layout Enumerate
Now you lock the original variable (O), see if it is equal to C1.
 If O==C1, then the result from the calculation is still valid.
 If O!=C1 then you have to go back to step 1.
\end_layout

\begin_layout Enumerate
If the calculation involved writing to the original variable (O), then you
 assign the second copy to the original (O=C2)
\end_layout

\begin_layout Enumerate
Now you have to unlock O again.
\end_layout

\begin_layout Standard
Of course it's done a bit more smartly than this in serious implementations,
 but it looks costly doesn't it? Unfortunately it is, but it's expected
 to improve a lot when we get hardware implementations.
 Well, actually we have hardware implementations, but not the sort that
 are targeted by mainstream compilers.
 A developer wishing to use Intel's (unfortunately buggy and off by default)
 TSX instructions will have to get dirty, probably with assembly, as these
 instructions were first available with the Haswell generation.
 If you're the sort whose processors come from Oracle or IBM, then your
 ecosystem might have had more time to nicely abstract these things away
 for you.
\end_layout

\begin_layout Standard
STM implementations do not have guarantees pleasing to the ear of a real-time
 engineer.
 Typically, operations will be done eventually, in arbitrary sequence.
 
\end_layout

\begin_layout Standard
Whatever your langauge is, someone's probably made an STM miplementation
 for it, but Clojure and Haskell are notable for using them as their primary
 means of synchronization.
 
\end_layout

\begin_layout Standard
Here's an example in Haskell (shamelessly taken from 
\begin_inset CommandInset citation
LatexCommand cite
key "key-2"

\end_inset

):
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "breaklines=true,frame=lrtb,language=Haskell,showstringspaces=false"
inline false
status open

\begin_layout Plain Layout

module Main where
\end_layout

\begin_layout Plain Layout

import Control.Monad
\end_layout

\begin_layout Plain Layout

import Control.Concurrent
\end_layout

\begin_layout Plain Layout

import Control.Concurrent.STM
\end_layout

\begin_layout Plain Layout

 
\end_layout

\begin_layout Plain Layout

main = do shared <- atomically $ newTVar 0
\end_layout

\begin_layout Plain Layout

          before <- atomRead shared
\end_layout

\begin_layout Plain Layout

          putStrLn $ "Before: " ++ show before
\end_layout

\begin_layout Plain Layout

          forkIO $ 25 `timesDo` (dispVar shared >> milliSleep 20)
\end_layout

\begin_layout Plain Layout

          forkIO $ 10 `timesDo` (appV ((+) 2) shared >> milliSleep 50)
\end_layout

\begin_layout Plain Layout

          forkIO $ 20 `timesDo` (appV pred shared >> milliSleep 25)
\end_layout

\begin_layout Plain Layout

          milliSleep 800
\end_layout

\begin_layout Plain Layout

          after <- atomRead shared
\end_layout

\begin_layout Plain Layout

          putStrLn $ "After: " ++ show after
\end_layout

\begin_layout Plain Layout

 where timesDo = replicateM_
\end_layout

\begin_layout Plain Layout

       milliSleep = threadDelay .
 (*) 1000
\end_layout

\begin_layout Plain Layout

 
\end_layout

\begin_layout Plain Layout

atomRead = atomically .
 readTVar
\end_layout

\begin_layout Plain Layout

dispVar x = atomRead x >>= print
\end_layout

\begin_layout Plain Layout

appV fn x = atomically $ readTVar x >>= writeTVar x .
 fn
\end_layout

\end_inset


\end_layout

\begin_layout Standard
This program runs for 800 milliseconds and has three threads.
 A transactional integer is made.
 Thread A prints the integer every 20 milliseconds, thread B adds two to
 the integer every 50 milliseconds and thread C subtracts one from the integer
 every 25 milliseconds.
 After 800 milliseconds the integer is 0 again.
 At least that's what I think it does.
 
\end_layout

\begin_layout Section
Channels
\begin_inset Index idx
status open

\begin_layout Plain Layout
Channels
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Channels as a method for communication are analogous to the concurrency
 in CSP, and convenient to verify and do formal analysis upon.
 The most known languages impementing them are Rust and Go.
\end_layout

\begin_layout Standard
Rust uses channels, futures and immutable copies.
 Channels are multi-sender, multi-receiver affairs, CSP-style:
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "breaklines=true,frame=lrtb,language={C++},numbers=left,showstringspaces=false"
inline false
status open

\begin_layout Plain Layout

fn main() 
\end_layout

\begin_layout Plain Layout

{   
\end_layout

\begin_layout Plain Layout

	let (tx, rx) = channel();   
\end_layout

\begin_layout Plain Layout

	let txclone = tx.clone();
\end_layout

\begin_layout Plain Layout

	
\end_layout

\begin_layout Plain Layout

	//proc denotes an anonymous function with function body being the stuff
 behind "proc()"
\end_layout

\begin_layout Plain Layout

	spawn(proc() tx.send("message"));
\end_layout

\begin_layout Plain Layout

	spawn(proc() txclone.send("another message"));      
\end_layout

\begin_layout Plain Layout

	spawn(proc() println!("{:s}, {:s}" ,rx.recv(), rx.recv()) ); 
\end_layout

\begin_layout Plain Layout

} 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
When sending a message over a channel in Rust, the data in the message will
 be duplicated.
 To improve efficiency, multiple tasks can share an object as if on a shared
 heap, provided that the object is immutable.
 You might have noticed that I cloned the transmitter.
 Why? Rust has no garbage collection, but still automatic memory management,
 which means that the moment at which an object can be deallocated from
 the heap need to be apparent at compile time.
 Therefore, two threads can't have references to the same heap object, in
 this case the transmitter.
 In Rust parlance, a thread owns the object and two threads can't own the
 same object.
\end_layout

\begin_layout Standard
Go takes a more imperative approach, and accidental data sharing is easier
 to do.
 Here we're doing the exact same thing in Go.
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "breaklines=true,frame=lrtb,showstringspaces=false"
inline false
status open

\begin_layout Plain Layout

package main
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

import "fmt"
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

func main() {
\end_layout

\begin_layout Plain Layout

  messages := make(chan string)
\end_layout

\begin_layout Plain Layout

  go func() { messages <- "message" }()
\end_layout

\begin_layout Plain Layout

  go func() { messages <- "another message" }()
\end_layout

\begin_layout Plain Layout

  msg := <-messages
\end_layout

\begin_layout Plain Layout

  msg2 := <-messages
\end_layout

\begin_layout Plain Layout

  fmt.Println(msg + " " + msg2)
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Section
Actors
\begin_inset Index idx
status open

\begin_layout Plain Layout
Actors
\end_layout

\end_inset


\end_layout

\begin_layout Standard
There are many implementations of the Actor model, but only two that I know
 of that matter: Erlang and Akka.
 
\end_layout

\begin_layout Subsection
Scala with Akka
\end_layout

\begin_layout Standard
Scala, a language, originally had its own message passing library, but this
 has been deprecated in favor of the Akka library, the essentials of which
 is included as standard in all recent distributions of Scala.
 The Akka actor library is an improvement on the Scala actor library which
 in turn is based on the Erlang actor model.
\end_layout

\begin_layout Standard
It's used like this:
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "breaklines=true,frame=lrtb,language=scala,numbers=left"
inline false
status open

\begin_layout Plain Layout

import akka.actor.Actor 
\end_layout

\begin_layout Plain Layout

import akka.actor.ActorRef 
\end_layout

\begin_layout Plain Layout

import akka.actor.ActorSystem 
\end_layout

\begin_layout Plain Layout

import akka.actor.Props 
\end_layout

\begin_layout Plain Layout

import scala.sys 
\end_layout

\begin_layout Plain Layout

import java.lang.Thread
\end_layout

\begin_layout Plain Layout

//Type declarations look like this: "nameOfObject:NameOfClass" with or without
 space.
\end_layout

\begin_layout Plain Layout

class DemoActor(printstr:String) extends Actor 
\end_layout

\begin_layout Plain Layout

{  
\end_layout

\begin_layout Plain Layout

  def receive = 
\end_layout

\begin_layout Plain Layout

  {     
\end_layout

\begin_layout Plain Layout

    case other: ActorRef =>
\end_layout

\begin_layout Plain Layout

    {     	
\end_layout

\begin_layout Plain Layout

      println(printstr)     	
\end_layout

\begin_layout Plain Layout

      other ! self      
\end_layout

\begin_layout Plain Layout

    }     
\end_layout

\begin_layout Plain Layout

    case _       => println("unknown message")   
\end_layout

\begin_layout Plain Layout

  } 
\end_layout

\begin_layout Plain Layout

}   
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

object Main extends App 
\end_layout

\begin_layout Plain Layout

{   
\end_layout

\begin_layout Plain Layout

  val system = ActorSystem("DemoSystem")     
\end_layout

\begin_layout Plain Layout

  val aActor = system.actorOf(Props(classOf[DemoActor], "a"))   
\end_layout

\begin_layout Plain Layout

  val bActor = system.actorOf(Props(classOf[DemoActor], "b"))   
\end_layout

\begin_layout Plain Layout

  aActor ! bActor   
\end_layout

\begin_layout Plain Layout

  Thread.sleep(3)   //let actors run for 3 milliseconds
\end_layout

\begin_layout Plain Layout

  scala.sys.exit() 
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The output of this is a sequence of type 
\begin_inset Quotes eld
\end_inset

a b a b a b
\begin_inset Quotes erd
\end_inset

 with each letter on a line of its own.
 The precise number of a's and b's printed to the console varies, but in
 general you don't have to scroll if your console is maximised.
 In another example, creating a million Akka actors in Scala takes about
 11 to 12 seconds on the lab computers.
\end_layout

\begin_layout Standard
Synchronous messaging is neither enforced nor recommended by the Akka developers
, but you can use bounded and blocking mailboxes.
 A bounded and blocking mailbox will block the sender of a message if the
 receiver's message queue is full but the minimum capacity is 1, so true
 synchrony is not achieved.
 To achieve true synchrony you need to manually use Await for each time
 you send a message.
 The reason it is not recommended is that new classes of bugs surface, something
 that might be advantageous to a life-critical application programmer, but
 not to the vast majority of programmers.
\end_layout

\begin_layout Standard
Akka actors interface neatly with other concurrency abstractions in Akka.
 More in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Actors,-Futures-and"

\end_inset

.
\end_layout

\begin_layout Standard
Akka actors have many interesting properties.
 For example, actor references are network aware, so one of our DemoActors
 could receive a message with an ActorRef to an actor on another continent
 and it would still respond correctly using the Akka Remote Protocol over
 TCP.
 Akka, unlike Erlang, enforces supervision in a similar manner as offered
 by Erlang's OTP.
\end_layout

\begin_layout Standard
Akka offers configurable message dispatchers, offering control over the
 number of underlying threads and number of messages an actor can process
 before the underlying thread jumps to the next actor.
 The default dispatcher uses a fork-join method to run the actors, but you
 can also use thread-pool or your own custom dispatcher.
\end_layout

\begin_layout Standard
Akka actors send messages as references by default, and unfortunately neither
 Java nor Scala enforces immutability of the underlying objects.
 To work around this, Akka provides optional deep copying of all messages.
\end_layout

\begin_layout Subsection
Erlang
\begin_inset Index idx
status open

\begin_layout Plain Layout
Erlang
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Both Erlang and OTP were developed at Ericsson, and today are used for critical
 infrastructure worth multiples of billions, like WhatsApp.
 Insert snarky remark about capitalism here.
 OTP stands for Open Telephony Platform,
\begin_inset Index idx
status open

\begin_layout Plain Layout
OTP
\end_layout

\end_inset

 an archaic name not reflecting current use.
\end_layout

\begin_layout Standard
For Erlang, the actor model is the beginning and the end.
 Erlang is structured around them; each actor has its own heap, which means
 that everything sent is physically copied.
 Erlang is also an eraly functional programming language, and has no loops.
 State is held as recursion arguments as the actors main function calls
 itself at the end of processing a message (or don't, if you want to terminate
 the actor).
\end_layout

\begin_layout Standard
flushing (timeout 0)
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "breaklines=true,frame=lrtb,language=erlang,numbers=left,showstringspaces=false"
inline false
status open

\begin_layout Plain Layout

-module(kitchen).
 
\end_layout

\begin_layout Plain Layout

-compile(export_all).
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

fridge2(FoodList) ->     
\end_layout

\begin_layout Plain Layout

	receive         
\end_layout

\begin_layout Plain Layout

		{From, {store, Food}} ->             
\end_layout

\begin_layout Plain Layout

			From ! {self(), ok},             
\end_layout

\begin_layout Plain Layout

			fridge2([Food|FoodList]);         
\end_layout

\begin_layout Plain Layout

		{From, {take, Food}} ->             
\end_layout

\begin_layout Plain Layout

			case lists:member(Food, FoodList) of                 
\end_layout

\begin_layout Plain Layout

				true ->                     
\end_layout

\begin_layout Plain Layout

					From ! {self(), {ok, Food}},                     
\end_layout

\begin_layout Plain Layout

					fridge2(lists:delete(Food, FoodList));                 
\end_layout

\begin_layout Plain Layout

				false ->                     
\end_layout

\begin_layout Plain Layout

					From ! {self(), not_found},                     
\end_layout

\begin_layout Plain Layout

					fridge2(FoodList)             
\end_layout

\begin_layout Plain Layout

				end;         
\end_layout

\begin_layout Plain Layout

		terminate ->             
\end_layout

\begin_layout Plain Layout

			ok     
\end_layout

\begin_layout Plain Layout

	end.
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

store(Pid, Food) ->     
\end_layout

\begin_layout Plain Layout

	Pid ! {self(), {store, Food}},     
\end_layout

\begin_layout Plain Layout

	receive         
\end_layout

\begin_layout Plain Layout

		{Pid, Msg} -> Msg     
\end_layout

\begin_layout Plain Layout

	end.
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

take(Pid, Food) ->     
\end_layout

\begin_layout Plain Layout

	Pid ! {self(), {take, Food}},     
\end_layout

\begin_layout Plain Layout

	receive         
\end_layout

\begin_layout Plain Layout

		{Pid, Msg} -> Msg     
\end_layout

\begin_layout Plain Layout

	end.
\end_layout

\end_inset


\end_layout

\begin_layout Section
Synchronous Execution
\end_layout

\begin_layout Standard
I'v'e only found one language that does this, and that is:
\end_layout

\begin_layout Subsection
Esterel
\begin_inset Index idx
status open

\begin_layout Plain Layout
Esterel
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Esterel may be the coolest implementation discussed here.
 It has very limited expressive power and is not freely available, but it
 has 
\emph on
exciting
\emph default
 properties: Threads in Esterel 
\emph on
execute in synchronous time
\emph default
.
 Put diferently, Esterel has a global clock that threads march in lockstep
 to! A thread has a loop and one cycle of that loop is ompleted per tick
 of the global clock.
 Esterel is completely deterministic; neither dynamic memory nor spawning
 of processes are supported.
 Signals are broadcast, and threads await and send signals.
 A signal is either precent in a cycle or it is not - the time of broadcast
 is abstracted away.
 Programs in Esterel are deterministic finite state machines.
\end_layout

\begin_layout Standard
Esterel is not a real-time language but since it is completely deterministic,
 simple testing should suffice for investigating time characteristics.
\end_layout

\begin_layout Standard
Esterel is hard to get hold of as a private individual, is a niche language
 and therefore we won't explore it in more detail.
\end_layout

\begin_layout Section
Parallel Statemens
\end_layout

\begin_layout Subsection
Occam's PAR
\begin_inset Index idx
status open

\begin_layout Plain Layout
Occam
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Unfortunately it proved troublesome to get one of the Occam compilers going
 - working with dead languages can be frustrating.
 Fortunately, many of the facilities offered in Occam can be replicated
 in other languages, for example by using Futures and Actors.
\end_layout

\begin_layout Standard
For example this (admittedly completely paper-programmed) Occam snippet...
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "frame=lrtb,language=ML,numbers=left,showstringspaces=false"
inline false
status open

\begin_layout Plain Layout

#INCLUDE "hostio.inc" 
\end_layout

\begin_layout Plain Layout

#USE "hostio.lib" 
\end_layout

\begin_layout Plain Layout

PROC Main(CHAN OF SP fs,ts)
\end_layout

\begin_layout Plain Layout

	SEQ
\end_layout

\begin_layout Plain Layout

		PAR
\end_layout

\begin_layout Plain Layout

			x = function(1)
\end_layout

\begin_layout Plain Layout

			y = function(2)
\end_layout

\begin_layout Plain Layout

		z = x+y
\end_layout

\begin_layout Plain Layout

		so.write.string.int(fs, ts, z, 0)
\end_layout

\begin_layout Plain Layout

		so.exit(fs,ts,sps.success)
\end_layout

\begin_layout Plain Layout

:
\end_layout

\end_inset


\end_layout

\begin_layout Standard
...
 can be replicated in Scala like this using futures:
\begin_inset CommandInset label
LatexCommand label
name "Future example"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "frame=lrtb,language=scala,numbers=left"
inline false
status open

\begin_layout Plain Layout

import scala.concurrent._ 
\end_layout

\begin_layout Plain Layout

import scala.concurrent.ExecutionContext.Implicits.global 
\end_layout

\begin_layout Plain Layout

import scala.concurrent.duration._ 
\end_layout

\begin_layout Plain Layout

import scala.language.postfixOps
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

object occ extends App 
\end_layout

\begin_layout Plain Layout

{   
\end_layout

\begin_layout Plain Layout

	def function(i: Int) = i*i
\end_layout

\begin_layout Plain Layout

	val x = Future {function(1)}   
\end_layout

\begin_layout Plain Layout

	val y = Future {function(2)}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	val z = for   
\end_layout

\begin_layout Plain Layout

	{     
\end_layout

\begin_layout Plain Layout

		xc <- x     
\end_layout

\begin_layout Plain Layout

		yc <- y   
\end_layout

\begin_layout Plain Layout

	} yield xc + yc   
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	val zval = Await.result(z, 0 nanos)   
\end_layout

\begin_layout Plain Layout

	println(zval) 
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Obviously, this is a good deal more cumbersome than the Occam syntax and
 probably has more overhead, but the general idea of 
\begin_inset Quotes eld
\end_inset

do these things in parallel and then combine them
\begin_inset Quotes erd
\end_inset

 is alive and well, though modern replacements tend to be less streamlined
 for this purpose and have additional bells and whistles.
\end_layout

\begin_layout Subsection
LabView's parallel arrows
\begin_inset Index idx
status open

\begin_layout Plain Layout
LabView
\end_layout

\end_inset


\end_layout

\begin_layout Standard
LabView is a proprietary graphical programming language, and as such a bit
 different from the other languages discussed here.
 LabView uses parallel statements.
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename /home/tormod/Documents/skole/fall2014/uniproject/doc/VisParProg.png
	lyxscale 70
	width 100text%

\end_inset


\end_layout

\begin_layout Standard
I had problems getting hold of labview screnshots with an appropriate license.
 Anyway, the basic concept can be easily eplained even with limited fidelity.
 Data flows along the arrows and the blocks hold functions that outputs
 new data.
 As the dataflows branch, you can see the potential for paralellism.
 Block a and block b are completely independent and LabView can (and will)
 therefore execute them in paralell.
 In the end it all gets fed into a sink, for example a controller or a print
 to memory or screen.
 
\end_layout

\begin_layout Standard
An Occam programmer may express the sequence pictured above like this:
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "frame=lrtb,language=ML,numbers=left,showstringspaces=false"
inline false
status open

\begin_layout Plain Layout

SEQ
\end_layout

\begin_layout Plain Layout

	do stuff
\end_layout

\begin_layout Plain Layout

	PAR
\end_layout

\begin_layout Plain Layout

		a
\end_layout

\begin_layout Plain Layout

		b
\end_layout

\begin_layout Plain Layout

	do more stuff
\end_layout

\end_inset


\end_layout

\begin_layout Standard
http://www.ni.com/white-paper/6422/en/
\end_layout

\begin_layout Standard
http://zone.ni.com/reference/en-XX/help/370622K-01/lvrtbestpractices/rt_priorities
/
\end_layout

\begin_layout Subsection
Futures
\end_layout

\begin_layout Standard
Here's a Rust example of the use of a Future
\begin_inset CommandInset label
LatexCommand label
name "Future example2"

\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "breaklines=true,frame=lrtb,language={C++},numbers=left,showstringspaces=false"
inline false
status open

\begin_layout Plain Layout

use std::sync::Future;
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

fn main()  
\end_layout

\begin_layout Plain Layout

{      
\end_layout

\begin_layout Plain Layout

	fn fib(n: u64) -> u64    
\end_layout

\begin_layout Plain Layout

	{     
\end_layout

\begin_layout Plain Layout

		// lengthy computation returning an uint     
\end_layout

\begin_layout Plain Layout

		12586269025   
\end_layout

\begin_layout Plain Layout

	}
\end_layout

\begin_layout Plain Layout

	let mut delayed_fib = Future::spawn(proc() fib(50)); 
\end_layout

\begin_layout Plain Layout

	println!("fib(50) = {}", delayed_fib.get());
\end_layout

\begin_layout Plain Layout

} 
\end_layout

\end_inset


\end_layout

\begin_layout Section
Actors, Futures and STM, Together.
 
\begin_inset Index idx
status open

\begin_layout Plain Layout
Actors
\end_layout

\end_inset


\begin_inset Index idx
status open

\begin_layout Plain Layout
Futures
\end_layout

\end_inset


\begin_inset Index idx
status open

\begin_layout Plain Layout
STM
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "sec:Actors,-Futures-and"

\end_inset


\end_layout

\begin_layout Standard
In Akka, futures are used by default to avoid blocking when waiting for
 a response, effectively allowing an actor to process several messages concurren
tly, if it needs to.
 This dramatically increases the complexity required to produce a deadlock,
 and does away with the classical 
\begin_inset Quotes eld
\end_inset

A waits on B and B waits on A
\begin_inset Quotes erd
\end_inset

 example entirely.
 For instance this program...
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "breaklines=true,frame=lrtb,language=scala,numbers=left"
inline false
status open

\begin_layout Plain Layout

import akka.actor.Actor
\end_layout

\begin_layout Plain Layout

import akka.actor.ActorRef
\end_layout

\begin_layout Plain Layout

import akka.actor.ActorSystem
\end_layout

\begin_layout Plain Layout

import akka.actor.Props
\end_layout

\begin_layout Plain Layout

import akka.agent.Agent
\end_layout

\begin_layout Plain Layout

import scala.sys
\end_layout

\begin_layout Plain Layout

import java.lang.Thread
\end_layout

\begin_layout Plain Layout

import scala.collection.mutable.ArrayBuffer
\end_layout

\begin_layout Plain Layout

import scala.util.Random
\end_layout

\begin_layout Plain Layout

import akka.util.Timeout
\end_layout

\begin_layout Plain Layout

import scala.concurrent._
\end_layout

\begin_layout Plain Layout

import scala.concurrent.ExecutionContext.Implicits.global
\end_layout

\begin_layout Plain Layout

import scala.language.postfixOps
\end_layout

\begin_layout Plain Layout

import akka.pattern.ask
\end_layout

\begin_layout Plain Layout

import scala.util.{Failure, Success}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

class FutureSTMActor(printstr:String, agent:Agent[String]) extends Actor
 {
\end_layout

\begin_layout Plain Layout

  var othermessagesanswered:Int = 0
\end_layout

\begin_layout Plain Layout

  def receive = 
\end_layout

\begin_layout Plain Layout

  {
\end_layout

\begin_layout Plain Layout

    case other: ActorRef =>
\end_layout

\begin_layout Plain Layout

    {
\end_layout

\begin_layout Plain Layout

      val response = other.ask("please reply")(50000)
\end_layout

\begin_layout Plain Layout

      response onComplete 
\end_layout

\begin_layout Plain Layout

      { 
\end_layout

\begin_layout Plain Layout

        case Success(result) => println("success: " + result); println(printstr
 + ": " + "STM Int says main thread in iteration: " + agent.get)
\end_layout

\begin_layout Plain Layout

        case Failure(failure) => println(failure)
\end_layout

\begin_layout Plain Layout

      }
\end_layout

\begin_layout Plain Layout

      othermessagesanswered += 1
\end_layout

\begin_layout Plain Layout

      println(printstr + ": " + othermessagesanswered.toString())
\end_layout

\begin_layout Plain Layout

    }
\end_layout

\begin_layout Plain Layout

    case "please reply" =>
\end_layout

\begin_layout Plain Layout

    {
\end_layout

\begin_layout Plain Layout

      sender() ! "this is a reply"
\end_layout

\begin_layout Plain Layout

    }
\end_layout

\begin_layout Plain Layout

    case s: String =>
\end_layout

\begin_layout Plain Layout

    {
\end_layout

\begin_layout Plain Layout

      println("got string: " + s)
\end_layout

\begin_layout Plain Layout

    }
\end_layout

\begin_layout Plain Layout

  }
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

object Main extends App  
\end_layout

\begin_layout Plain Layout

{
\end_layout

\begin_layout Plain Layout

	val agent = Agent("0"*10)
\end_layout

\begin_layout Plain Layout

	val system = ActorSystem("DemoSystem")
\end_layout

\begin_layout Plain Layout

    val aActor = system.actorOf(Props(classOf[FutureSTMActor], "a", agent))
\end_layout

\begin_layout Plain Layout

    val bActor = system.actorOf(Props(classOf[FutureSTMActor], "b", agent))
\end_layout

\begin_layout Plain Layout

    for (x <- 0 to 10)
\end_layout

\begin_layout Plain Layout

    {
\end_layout

\begin_layout Plain Layout

      println("m: " + x.toString)
\end_layout

\begin_layout Plain Layout

      agent send ((x.toString) * 10)
\end_layout

\begin_layout Plain Layout

      println("m: " + agent.get.toString)
\end_layout

\begin_layout Plain Layout

      Future{ aActor ! bActor }
\end_layout

\begin_layout Plain Layout

      Future{ bActor ! aActor }
\end_layout

\begin_layout Plain Layout

      if(x%1==0) { Thread.sleep(2) }
\end_layout

\begin_layout Plain Layout

    }
\end_layout

\begin_layout Plain Layout

    Thread.sleep(1000)
\end_layout

\begin_layout Plain Layout

    scala.sys.exit()
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
...
 will not deadlock.
 Moreover, the two actors will not even be in synchrony.
 Since they wait for each other with futures, they're not really waiting
 at all!
\end_layout

\begin_layout Standard
Now, you think we may be covered, but the problem with messages is one of
 synchronization.
 How do you make sure that an entire system of actors all have the same
 value, for example money in your bank account? One way to do it is to use
 STM, as we here do, synchronizing state across actors using Agents, which
 are inspired by Clojure's STM.
 As expected, the STM Agent is synchronized through the entire run, even
 though nothing else among the agents are.
\end_layout

\begin_layout Section
Scheduling Lightweight Threads
\begin_inset Index idx
status open

\begin_layout Plain Layout
Scheduling
\end_layout

\end_inset


\end_layout

\begin_layout Standard
If you are goin to run N lightweight threads on M OS threads, you'll have
 to spread the tasks over, or dispatch them to, the OS threads, somehow.
 What I'm saying is that you have to write a scheduler.
 As someone who has done that while writing this: Oy vey, woe be you.
 It's not a particularly easy task, but some smart people have thought about
 it before you and I have:
\end_layout

\begin_layout Subsection
Thread-pool dispatching
\begin_inset Index idx
status open

\begin_layout Plain Layout
thread-pool dispatching
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The tasks to be run are divided into groups of assumed equal load and given
 to the real threads for execution.
 This method is divided into first a divide and then a conquer phase.
 If one group of tasks turns out to take longer than another the real thread
 with the easier task group is left idling.
\end_layout

\begin_layout Subsection
Fork-join dispatching
\begin_inset Index idx
status open

\begin_layout Plain Layout
fork-join dispatching
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Juicy stuff.
 This is what Go and Akka uses by default.
\end_layout

\begin_layout Standard
Fork-join is similar to thread-pool, but uses something called work stealing.
 With work stealing, a thread that finishes its tasks early can 
\begin_inset Quotes eld
\end_inset

steal
\begin_inset Quotes erd
\end_inset

 tasks from a thread that's still busy.
 What happens is that the tasks are grouped in a single group and pushed
 on a stack.
 Each real thread can then pop a group of task and either split the group
 and push the resulting groups or execute the group.
 In general, real threads will only execute very small groups, splitting
 groups instead if they're too large.
 Task groups should be considered small enough when the expected overhead
 of worrying about their size is larger than the expected cost of a single
 group being too large.
 The benefit of this method over thread-pool is that the divide and conquer
 phases are interleaved.
 There are a lot more task groups than threads, so a misjudgment of the
 complexity of a single task group should have smaller consequence.
\end_layout

\begin_layout Standard
The 
\begin_inset Quotes eld
\end_inset

work stealing
\begin_inset Quotes erd
\end_inset


\begin_inset Index idx
status open

\begin_layout Plain Layout
work stealing
\end_layout

\end_inset

 term comes from an alternative implementation where the N real threads
 split the tasks into N task groups which each real thread finally splits
 and places on its own work stack.
 Once a real thread is done with its own task groups it will try to steal
 task groups from other real thread's stacks.
 If there's no work to find there it will look to an input queue of work
 common to all N real threads.
\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Standard
The popular approaches taken to concurrency in modern languages can be roughly
 divided into three: The actor model, channels and software transactional
 memory.
 The three approaches come from different mindsets and priorities.
 Users of the actor model often use it to create distributed, parallel,
 fault-tolerant systems.
 Users of CSP often want lower-level concurrency mechanisms that are easier
 to reason about and more predictable.
 STM users generally want C-like concurrency with the synchronisation chores
 handled by the langauge.
 <-weak on STM.
 Fix.
\end_layout

\begin_layout Paragraph
The differences between CSP and actor model
\end_layout

\begin_layout Itemize
CSP threads are anonymous, actors are named.
\end_layout

\begin_layout Itemize
CSP communication is synchronous, actor communication is asynchronous.
\end_layout

\begin_layout Itemize
CSP communication is multi-sender, multi-receiver, actor communication is
 one-to-one.
\end_layout

\begin_layout Part
Proposal
\end_layout

\begin_layout Standard
A recurring theme in discussing these topics online seems to be a need for
 predictability.
 POSIX threads are not predictable, but are or may be perceived as more
 predictable than lightweight threads with lots of stuff happening underneath
 in a non-obvious manner.
\end_layout

\begin_layout Standard
I propose an implementation that is as simple and deterministic as possible,
 providing guarantees like 
\begin_inset Quotes eld
\end_inset

all threads get to run a decent amout
\begin_inset Quotes erd
\end_inset

.
 Exposed functionality should be something like:
\end_layout

\begin_layout Enumerate
Parmap, a very simple mapping of one array to another of type 
\begin_inset Formula $arrayA[x]=f(arrayB[x])$
\end_inset

 for all elements x.
 Executed in parallel.
\end_layout

\begin_layout Enumerate
Futures, parallel computation
\end_layout

\begin_layout Enumerate
Lightweight threads with channels.
\end_layout

\begin_layout Part
Prototype
\end_layout

\begin_layout Section
Scheduler
\end_layout

\begin_layout Standard
Of paramount importance in implementing lightweight threads is the scheduler.
 Both Go and Akka use a work-stealing scheduler and this seems to be the
 industry standard.
 Because it's simple and I'm not very good at C programming I made a simpler
 scheduler in which the worker threads compete for the lightweight threads.
 For lightweights that don't do much the result is catastrophic as worker
 threads compete for mutexes:
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename /home/tormod/Documents/skole/fall2014/uniproject/doc/lightLoadedLightThreadsDumbSched.svg
	lyxscale 70
	width 100text%

\end_inset


\end_layout

\begin_layout Standard
For lightweight threads that do a fair amount of work the result is a lot
 better:
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename /home/tormod/Documents/skole/fall2014/uniproject/doc/hevyLoadedLightThreadsDumbSched.svg
	lyxscale 70
	width 100text%

\end_inset


\end_layout

\begin_layout Standard
Note that the time given on the y axis can not be compared across graphs,
 as the amount of repetitions is different.
 There are three lightweight threads, two of which sends messages to each
 other.
 That's why we speedup when moving from two to three workers is so lacklustre
 and performance only improves until we have three threads.
 The perfect amount of worker threads seems best determined by the programmer,
 who knows how the light threads will communicate, and thus what the real
 amount of paralellism is.
 That said, thread-pooling or work-stealing schedulers deal close to optimally
 with surplus threads.
\end_layout

\begin_layout Standard
An important point can be observed from this: You can make your code slower
 by throwing more threads at it! Even a good scheduler still has a lot of
 overhead and that overhead may take more time than the actual work, if
 that amount of work is small enough.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "llnl.gov pthreads"
key "key-1"

\end_inset

https://computing.llnl.gov/tutorials/pthreads/
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Haskell STM Example"
key "key-2"

\end_inset

https://www.haskell.org/haskellwiki/Simple_STM_example
\end_layout

\begin_layout Standard
\begin_inset CommandInset index_print
LatexCommand printindex
type "idx"

\end_inset


\end_layout

\end_body
\end_document
